Joint work with Brooke Spring 2023
January 20th: Discuss the multiplex community detection article, introduce the network datasets and go over the code
Run findingk.m with the data (cell array) and find k, kc, kpr. If k<3 for any of the layers, discard the results. Similarly, if k> 20 for any of the layers, discard 
the results. If this is the case, fix k=6 for each layer, kc=3, kpl=3. Run MX-ONMTF with modularity density for real networks.
January 27th (need to change meeting time): initially run the algorithm with different K rather than learning it from data, go over the initial run of the algorithm on 20 ERN networks and discuss potential problems
Feb 3rd (need to change meeting time): change delta in EigenGap to see if we get larger K, start with 0.5. For now, set kc=K (assume all the communities are common across subjects). Sparsify the networks.
1) Threshold (input will be A): For each subject, you can take all the edge values, order them and keep only the top 20% (make it higher to ensure that the resulting network is still connected, no isolate nodes), you need to make
sure that you take the same percentage of edges across all subjects. 
- use the threshold A, \hat{A} and rerun EigenGap to check how K changes
- get the visualization code from Meiby
Feb 10th: use K=6, focus on visualizing the clusters for each layer. Next, transfer the maps to topomaps. (share topomap code)
Feb 17th: Focus on visualizing the clusters, determine clusters that occur in the majority of the layers and focus on visualizing clusters that are common across the
majority (>10 layers), find out why the node labels differ for the same cluster across layers. Implement thresholding (described above) to the input A matrices and rerun the
algorithm.
Feb 24th: create intercluster strength of all edges between the cluster nodes identified (with A threshold of 0.9 matrix). For the EEG brain plots, remove the lines and edit label font to be more visable.
Email the figures for the paper by Wednesday. If time, play with thresholds (delta, eiggap)
March 3rd (cancel). Meeting 11:30Am FRiday .
March 10th: spring break
March 17th: move to Thursday 16th, 10AM. Focus on "Using connectome-based predictive modeling to predict individual behavior from brain connectivity" paper
Brainstorm ways to relate either kc or kp to identifying individual subjects and metrics to do so. Can also review "Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity"
-Possible other algorithms focusing on private communities.
March 24th: Starting with MX-ONMTF, identify the whole set of communities, i.e., both common and private. For each node, generate a community membership vector across subjects.
g_i(k)=Number of times node i is assigned to the kth community across 20 subjects, where k=1,2,3,....,K (total number of communities.) Normalize g_{i} to obtain a 
probability mass function p_{i}=g_{i}/sum_{i} g_{i}. Compute the entropy for each node, H_{i}, based on p_{i}, H_{i}= - sum p_{i}log2p_{i}. This number should always 
be positive. Small entropy values would imply high consistency across subjects and vice versa. We can plot H_{i} over the brain topomap.
Implement a similar idea with GenLouvain algorithm, \gamma=1, \omega=1 to start with. 
March 31st: fix the code based on the new formulas, clarified ideas. p_{i} = g_{i}/sum_{k}g_{i}(k),p_{i} is a vector K x 1 
H(i) = -sum(k)p_{i}(k)log2p_{i}(k)
April 7th: visualize the entropy values in a topoplot; study reproducibility of the algorithm: take one subject out, run the algorithm, obtain the communities, repeat this 
procedure 20 times (take a different subject out in each run); quantify the consistency of the results-->compute NMI between the community structure of the original run
(the one with 20 subjects) and each of the 20 runs, calculate the mean NMI
April 14th: find the ks with the new data, and work with processing the data for the old one.
April 21st:
April 27th: last meeting
